---
layout:     post
title:      计算机基础
subtitle:   
date:       2022-12-6
author:     
header-img:
catalog: true
tags:
    - 计算机基础
---
## 计算机的简略发展史
### 电子管时代
背景：为了军方的计算要求，比如弹道轨迹计算，人们的需要一个能代替人脑的计算装置。

当时的计算机会有很多逻辑处理元件，它们在高低电压（可以表示01的二进制）下用线路连接起来实现计算的功能。

当时的主要逻辑元件是电子管，体积大，耗电量大。此时的计算机只能识别0101的二进制数，所以只能用机器语言来编程。

### 晶体管时代
背景：希望计算机体积、耗电量、计算能力等方面比上个时代更出色。

晶体管的电气特性可以替代电子管，而且晶体管的体积比电子管小很多，这也意味着此时的计算机要小很多。
并且出现了面向过程的程序设计语言和操作系统的雏形，制造一台计算机大概需要几万到几十万的晶体管，并且需要用手工的方式把晶体管焊接到电路板上，就非常容易出错。

### 中小规模集成电路时代
集成电路的技术让我们计算机变得越来越小，同时功耗更低，可靠性也比手动焊接的晶体管更高，
此时的计算机主要用于科学计算，一些高级语言同时产生，并出现分时操作系统

### 超大规模集成电路时代
随着集成电路工艺的不断提升，出现了大规模和超大规模集成电路，此时开始出现微处理和微型计算机，也就是我们现在家用的计算机，就拿苹果的A13处理器来说，每一个逻辑元件在其中不超过7纳米，一个指甲盖大小的cpu就集成了85亿个晶体管。

## 计算机的硬件组成
### 冯诺依曼体系
冯诺依曼就提出了存储程序的概念，将指令以二进制代码的形式事先输入到计算机的内存里，然后内存根据里面存储的指令从首地址也就是第一条指令开始按顺序一条一条的执行，直到程序执行结束，这种自动执行的机制比人工操作使计算机的计算效率大大提升。

冯诺依曼体系是以运算器为核心的，我们现代的计算机是以存储器为核心

### 现代计算机
首先，计算机最基本的5大组成部分分别为：输入设备(比如键盘), 存储器(比如内存), 运算器(cpu), 控制器(cpu), 输出设备(显示器)。运算器和控制器等部件
被集成在一起，统称为中央处理单元。

CPU的功能：
程序控制。CPU 通过执行指令来控制程序的执行顺序。
操作控制。一条指令功能的实现需要若干操作信号配合来完成，CPU 产生每条指令的操作信号并将操作信号送往对应的部件，控制相应的部件按指令的功能要求进行操作。
时间控制。CPU对各种操作进行各类时间上的控制
数据处理。CPU通过对数据进行算术运算及逻辑运算等方式进行加工处理，数据加工处理的结果被人们所利用。所以，对数据的加工处理也是 CPU 最根本的任务。
此外，CPU还需要对系统内部和外部的中断(异常)做出响应，进行相应的处理。

* 运算器负责程序运算与逻辑判断等操作
* 控制器负责协调各周边组件与各单元间的工作

控制器包括：
程序计数器PC（也叫指令计数器）。存放指令，数据的地址。
指令寄存器IR。根据程序计数器存放的地址取出指令后，存放在这。
指令译码器。指令译码器翻译指令要做的事，分析操作码，向控制器发出具体的控制信号。
地址寄存器AR。保存当前 CPU 所访问的内存单元的地址，直到内存的读写操作完成。因为 CPU 和内存有着操作速度上的差异。

> 指令包括操作码和地址码，地址码存的是这个指令用到的数据的地址。

运算器包括：
算术逻辑单元ALU。负责处理数据，算术运算和逻辑运算。
累加寄存器。累加器，是一个通用寄存器。当ALU执行运算时，为其提供工作区，暂存数据，运算完成后放回累加器中。
数据缓冲寄存器。在对内存储器进行读写操作时，暂存 cpu 和 主存（内存）间要传输的数据。
状态条件寄存器。存储一些算术指令和逻辑指令产生的状态标志和控制标志。

例题：计算机执行指令的过程中，需要由CPU的控制器产生每条指令的操作信号并将信号送往相应的部件进行处理，以完成指定的操作。

指令寻址方式：
立即寻址方式：操作数直接在指令中，速度快，灵活性差
直接寻址方式：指令中存放的是操作数的地址，存放在主存。
间接寻址方式：指令中存放了一个地址，这个地址对应的内容是操作数的地址。都存放在主存。
寄存器寻址方式：寄存器存放操作数
寄存器间接寻址方式：寄存器内存放的是操作数的地址，而操作数存放在主存中。

![img.png](/img/计算机硬件组成.png)

上图的实线是数据线，是数据交换的通路，虚线是控制线和反馈线，是传递命令的通路

- 首先我们的数据通过输入设备会被加工程计算机能够识别的0101的形式，我们直接输入的代码计算机是不认识的。
- 然后经过输入设备处理的数据，先存到了主存里（控制器控制输入设备），存储器可以存放数据和程序指令
- 然后控制器可以直接从存储器里取得所需要执行的程序指令，取得指令后，控制器会分析指令要做什么（指令分为操作码和地址码），分析的就是操作码，到底要干嘛
- 假设分析出来是读取数据的操作，也就是从存储器中取一个数据给运算器，那么读取数据的地址就在写在地址码里面，这时运算器就去就告诉存储器要取数据的地址，然后存储器直接把数据传递给运算器
- 最后运算结束，运算结果会返回存储器，存储器可以直接把结果返回给输出设备（在控制器的控制下）
- 最后输出设备，比如显示器上就看到我们想要的数据

我们拿一个实际的javascript代码来举例:

假设在我们的JS代码里，运行代码 let a = 1 + 1，此时上述的5大计算机部件如何处理的呢？
- 首先键盘输入代码let a = 1 + 1将被解析为2进制代码，在控制器的控制下放入了内存
- 然后内存存储完毕， CPU的控制器开始从内存里取出指令，分析出指令是一个加法操作（先让 1+1运算，后面才会把1+1运算的结果赋值给变量a）
- 然后控制器控制运算器，运算器直接从内存里取出数据两个1，做一个加法运算得出结果，并返回给存储器，存储到一个内存的地址里
- 然后控制器接着执行第二条指令（let a = 2），因为之前2已经被算出来了，第二条指令是赋值操作了（把1+1的值赋给变量a，a其实就是一个内存地址而已）
- 此时CPU的控制将控制CPU的运算器做1+1的加法运算，并得出结果2
- 最后执行指令完毕，如果我们要打印console.log(a)的话，a因为本质上是一个内存地址，cpu会根据内存地址，找到这个地址里存放的值，也就是console.log显示的值
- 获取到要显示的值后，存储器直接将数据传给显示器，这样我们就可以在屏幕上看到2这个结果了

### 多级存储结构
多级系统的划分是为了解决存储容量、成本和速度之间的矛盾。

速度从快到慢：
- CPU 的寄存器
- cache（相联存储器）（主存和CPU速度不匹配，需要 cache）
- 内存（主存）RAM 和 ROM
- 外存（辅存）硬盘、光盘、U盘等

采用虚拟存储器扩大了用户编程的地址空间。

多级存储结构包括 cache 缓存-主存层次和主存-辅存层次。前者缓和 CPU 和主存之间的速率矛盾，后者逻辑上扩大主存空间，前者实现是通过硬件，后者是通过软硬件。

局部性原理是层次化存储结构的支撑
- 时间局部性：刚被访问的内容，立即又被访问。
- 空间局部性：刚被访问的内容，临近的空间很快被访问。

### flynn体系结构
![img.png](/img/flynn体系结构.png)

### cpu 流水线技术
处理指令是按照“取指”-“分析”-“执行”。没使用流水线技术就是每个指令走完这个过程后，再对下个指令重复这个步骤。

使用流水线技术后：
![img.png](/img/流水线技术.png)

流水线执行时间：(t1+t2+t3) + (n-1)t。其中 t 是流水线周期中执行时间最长的一段。比如取指4，分析2，执行2单位之间。t就是4。

例:若指令流水线把一条指令分为取指、分析和执行三部分，且三部分的时间分别是取指2ns，分析2ns，执行1ns。那么，流水线周期是?100条指令全部执行完毕
需要的时间就是?

解答:(2+2+1)+(100-1)x2=203ns

通常可以将计算机系统中执行一条指令的过程分为取指令、分析和执行指令3步，若取指令时间为4△t，分析时间为2At，执行时间为3t，按照顺序方式从头到尾执行
完600条指令所需时间为(5400)△t;若按照执行第i条、分析第i+1条、读取i+2条重叠的流水线方式执行指令，则从头到尾执行完600条指令所需时间为(2405)t。

### 主存存储单元
按字编址:存储体的存储单元是字存储单元，即最小寻址单位是一个字，

按字节编址:存储体的存储单元是字节存储单元，即最小寻址单位是一个字节。

> 1 字节等于 8 bit

根据存储器所要求的容量和选定的存储芯片的容量，就可以计算出所需芯片的总数，即: 总片数 = 总容量/每片的容量

例: 若内存地址区间为4000H~43FFH，每个存储单元可存储16位二进制数，该内存区域用4片存储器芯片构成，则构成该内存所用的存储器芯片的容量是多少?

例：在计算机系统中总线宽度分为地址总线宽度和数据总线宽度。若计算机中地址总线的宽度为32位，则最多允许直接访问主存储器()物理空间。

宽度为 32 位，就是有 32 个 bit 位，能够表示2的32次方个地址。2的32次方可以分解为2的3次方乘2的10次方乘2的10次方乘2的10次方。
2的10次方等于1K。最后计算出等于4GB。

设内存按字节编址，若8Kx8存储空间的起始地址为7000H，则该存储空间的最大地址编号为()。
按字节编址，每个地址块能存放一个字节，即八个bit，即(x - 7000H + 1) * 8bit = 8k * 8bit

#### 磁盘存储
![img_1.png](/img/磁盘存储.png)

磁盘上每个区域就是一个扇区，每个环区就是一个磁道。

![img.png](/img/磁盘存储练习题.png)

## 计算机网络的定义
计算机网络定义为“以能够相互共享资源的方式互连起来的自治计算机系统的集合”。

主要表现在：
- 目的是实现计算机资源的共享
- 分布在不同位置多台独立的“自治计算机”
- 通信必须遵循共同的网络协议

按分布范围，计算机网络里有局域网LAN和广域网WAN, 其中局域网的代表以太网，以及这两种网络最重要的区分点，局域网基于广播技术，广域网基于分组交换技术。

### 概念
带宽：在计算机网络中，网络带宽是指在单位时间（一般指的是1秒钟）内能传输的数据量，比如说你家的电信网络是100兆比特，意思是，一秒内最大的传输速率是100兆比特。
吞吐量：吞吐量表示在单位时间内通过某个网络（或信道、接口）的数据量。

带宽是说的是最大值速率，吞吐量说的是某时刻速率。但吞吐量不能超过最大速率。

时延是指数据（报文/分组/比特流）从网络（或链路）的一端传送到另一端所需的时间。单位是s。 时延分一下几种：
* 发送时延：就是说我跟你说话，从我开始说，到说话结束这段时间，就是发送时延。
* 传播时延：信道上第一个比特开始，到最后一个比特达到主机接口需要的时间就是传播时延。
* 排队时延：分组在经过网络传输时，要经过很多的路由器。但分组在进入路由器后要先在输入队列中排队等待处理。在路由器确定了转发接口后，还要在
输出队列中排队等待转发，这就产生了排队时延。排队时延的长短往往却决于网络当时的通信量，当网络的通信量很大时会发生排队溢出，是分组丢失。
* 路由器或主机在收到数据包时，要花费一定时间进行处理，例如分析数据包的首部，这就产生了处理时延。

往返时间（RTT）：在计算机网络中，往返时间也是一个重要的性能指标，它表示从发送方发送数据开始，到发送方收到来自接收方的确认（接受方收到数据
后便立即发送确认）总共经历的时间

### 局域网
按照网络覆盖范围划分，计算机网络可划分为局域网、城域网和广域网。

局域网是有限区域内（如办公室）的多台计算机通过传输介质互连所组成的封闭网络。可实现数据通信和资源共享，具有较高的数据传输效率和较低的时延。

802.3z 标准提到多模光纤，单模光纤 和 STP 相关的标准（数据传输速率达到千兆的标准）。802.ab 提到 UTP 相关标准。

![1b903b9cfa892e1d1ccd65a1667e779](/img/计算机基础/网络拓扑结构.png)

#### 网络拓扑结构
##### 总线型
1. 采用集线器。集线器内部采用一条总线进行数据的传输。
2. 竞争式访问。同一时刻只允许一个用户进行信息的传递。
3. 采用 CSMA/CD 机制。这个机制就是竞争式访问的协议。

##### 星型
交换机没特殊说明，默认为二层交换机，属于数据链路层。

##### 环型（令牌环网）
有令牌（token）就能发送数据。

![50256d543a840d6442a88e98e200203](/img/计算机基础/网络类型.png)

虽然上图显示以太网的缺点重负载延迟明显，但现在以太网发展迅速，数据延迟都很低了。

##### 网状
任何两个计算机之间都会有一条网线将他们连接。

### 以太网
以太网是一种局域网技术，其规定了访问控制方法、传输控制协议、网络拓扑结构、传输速率等，完成数据链路层和物理层的一些内容，
它采用一种称作CSMA/CD的媒体接入方法，另外的一些局域网技术，比如无线局域网等。

#### 交换式以太网
交换式以太网使用以太网交换机作为核心设备进行组网，与共享型局域网采用集线器等作为中间设备有所不同。

数据转发方式：

如果目标地址(目的MAC)在MAC地址表中存在，则交换机将数据转发至该端口;如果没有，交换机就向除接收到该数据帧的端口外的其他所有端口广播该数据帧。

MAC地址表更新机制

交换机基于数据包的源MAC地址学习并存入MAC地址表。如果交换机接收到的数据包其源地址在MAC地址表中没有，交换机学习该MAC地址并将其加入MAC地址表。

交换机如果发现一个帧的入端口和MAC地址表中源MAC地址的所在端口不同，交换机将MAC 地址重新学习到新的端口。

注意:交换机MAC地址表的老化时间是300秒:

##### 数据转发机制
交换机的三种交换模式：
* 快速转发：交换机接收到（数据帧前14个字节，7个字节的帧前缀，1个字节的起始帧和6个字节的目的地址)也就立刻转发该数据帧，
* 碎片丢弃：不保存整个数据帧，只需要接收64个字节，就开始转发数据帧，超过64个字节就视为碎片丢弃。
* 存储转发：转发前，将整个数据帧读取到内存里。

#### 类型
交换式以太网使用以太网交换机作为核心设备进行组网，与共享型局域网采用集线器等作为中间设备有所不同。

#### 数据帧格式
从前往后：前导码（8字节）-目的地址（源MAC）（6字节）-源地址（目的MAC）（6字节）-类型（2字节）-数据（46到1500字节）-帧校验序列（4字节），最小帧长64字节（不包括前导码）。
最小帧长是根据网络中检测冲突的最长时间确定的。

> 类型即可以表示数据字段长度也可以表示上层协议类型(2B)
> 数据不足46字节会补足
> 校验即CRC校验

mac 地址采用6字节48比特位

### 冲突域和广播域

集线器构成一个冲突域和一个广播域。无法分割广播域和冲突域。

> 在集线器上，监控一个端口就能捕获其他所有端口的通信流量。

交换机每个端口独立构成一个冲突域，所有端口共同构成一个广播域。可以分割冲突域，无法分割广播域。

> 每个端口收发数据的时候不会引起冲突。如果发送广播包，广播包能到达交换机的所有范围区域。

路由器每个端口是独立的广播域。可以分割冲突域和广播域。

> 路由器接收到网络信息不会进行转发

![img.png](/img/冲突域和广播域计算.png)

### VLAN（虚拟局域网）
虚拟局域网解决在广播域中产生大量广播导致与数据流竞争带宽，消耗设备资源的问题。

虚拟局域网将一台物理的交换机通过VLAN的划分，变成逻辑上完全独立的交换机，每个VLAN都是一个单独的广播域。

好处：
* 安全性:通过VLAN的划分隔离不同的部门，减少保密信息遭到破坏的可能性。（VLAN之间无法直接通信，需要配置）
* 性能提高:将二层网络划分成多个逻辑工作组(广播域)减少网络间不必要的数据流并提升性能。
* 缩小广播域:减少一个广播域上的设备数量。

### 层次化结构设计
三层：服务器-局域网核心交换机-局域网汇聚交换机-局域网接入交换机-用户

![img.png](/img/层次化结构设计.png)

### 综合布线技术
![img.png](/img/综合布线技术.png)

### 网络协议
网络协议是计算机网络和分布系统中互相通信间的对等层实体交换信息时必须遵守的规则的集合。

### OSI模型
它是一套普遍适用的规范，使全球计算机可进行通信。

OSI 中定义了每层的作用，定义每层作用的是协议，协议是约定，具体内容是规范。

下层为上层提供服务，每层实现功能的活动元素称为实体。

不同主机的相同层次称为对等层，使用相同的网络协议。

#### 物理层
物理层是规定传输媒体接口的标准，比如说，规定了电气特性，信号的电平用+10V - +15V表示二进制的0，用-10V - -15V表示二进制的1，只要网线能表
示这个特性，就不管你用什么材料了。

##### 光纤宽带上网是以什么样的形式传输数据呢？
首先计算机网卡传输出来的数据是电信号，光纤传输的是光脉冲信号，有光脉冲表示1，无光脉冲表示0。而可见光的频率大约是10的8次方MHz，因此光纤通
信系统的带宽远远大于其它各种传输媒体的带宽，所以我们计算机传输数据需要先把电信号转为光信号，然后光信号快到服务器的时候，再把光信号转为电信号。

##### 物理层中继器
线路上传输的信号功率会逐渐衰减，衰减到一定程度时将造成信号失真，因此会导致接收错误。中继器可以对信号进行再生和还原，增加信号的传输距离。

需要注意的是，中继器两端连接不同的网段，而不是子网。不同的网段就是不同路由器连接的网络。

#### 数据链路层
数据链路层任务：
* 封装成帧。数据链路层并不是无脑转发网络层的信息，需要封装。封装的网络数据包，在链路层就叫数据帧。
* 透明传输。透明传输是指不管任何信息，都要原原本本的传输。帧的数据部分可能有跟帧首部完全一样的字符，这时候就要采取一定的措施。
* 差错控制。差错控制是遗漏的信息会重新发送。差错控制的方法有CRC循环冗余码。
* 差错纠正。差错纠正是链路层知道1，2，3，4，5个文件，丢失的两个文件到底是哪两个，并且能通过重新发送没有的文件来纠正。
* 流量控制。比如说发送方发送速度特别快，接收方接收速度特别慢，会造成传输出错。流量控制的方法有滑动窗口协议，以及选择重传协议。
这里需要注意的是，传输层TCP也有流量控制功能，区别在于TCP是端到端的流量控制，链路层是点到点（比如一个路由器到下一个路由器）。

## 数据通信
信号：通信系统中信息的传递需要载体，载体被称为信号，通常以电磁波形式存在。

在通信里面会用相同时间间隔的一个符号来表示一个二进制数字。

失真分为信号波形可以识别和无法识别的情况。受影响的情况有：带宽受限，噪声，干扰和失真。

![img.png](/img/通信系统模型.png)

### 信道特征
![img.png](/img/计算机基础/信道特征.png)

码元速率（波特率）表示单位时间内能够发送多少个码元。一般用 `B` 表示，单位是 B。

采样频率必须大于信道带宽的两倍才能保证信号接收到之后不会失真。带宽在模拟信道内单位是赫兹，频率单位是赫兹，是时间的导数，类似每秒拍手一次。

码元：相同时间间隔里的一个符号来表示一个二进制数字。码元的种类数决定了码元能携带的信息量，也就是bit位。16 种码元，需要4个 bit 来构成。每一个码元
都能携带4个bit的信号量。

S/N 即信噪比，通常数值较大，一般用分贝表示。dB = 10log以10为底(S/N)。

> log₈2我们读作log以8为底，2的对数。具体计算方式是2的3次方为8，及以8为底2的对数就是3。

经过C = Wlog2（1+S/N）（1+S/N被约为了1024）计算后，当分贝数为30dB时，可以简化成C = 10W。（信噪比可能是固定是1000的，所以能简化）

设信道带宽为4kHZ，信噪比为，30dB，按照香农定理，信道最大数据速率约等于 40KB/s

采用幅度-相位复合调制技术，由4种幅度和8种相位组成 16 种码元，若信道的数据速率为 9600 b/s.则信号的波特率为(2400)Baud

![img.png](/img/计算机基础/信道特征两理论计算.png)

### 调制技术
![img.png](/img/计算机基础/调制技术图形.png)

![img_1.png](/img/计算机基础/调制技术.png)

ASK 通过改变幅度来表示1和0；FSK 改变频率；PSK 改变初始相位。

模拟数据转换成数字信号步骤：采样-量化-编码。

采样：在模拟数据上取时间间隔的时间点。

量化：量化模拟数据时间点上的数据为数值。

编码：将量化的数值从十进制转为二进制数据。

设信道的码元速率为300波特、采用4相DPSK调制，则信道的数据速率为600b/s。

设模拟信号的最高频率为10MHz，采样频率必须大于(20MHz)时，才能使得到的样本信号不失真，如果每个样本量化为256个等级，则信道的数据速率是(160Mb/s)。

## 为什么计算机内部选择二进制数表示
- 技术实现简单，计算机是由逻辑电路组成，逻辑电路通常只有两个状态，开关的接通与断开，这两种状态正好可以用 “1” 和 “0” 表示;
- 易于进行转换，二进制与十进制数易于互相转换;
- 适合逻辑运算,逻辑代数是逻辑运算的理论依据，二进制只有两个数码，正好与逻辑代数中的“真”和“假”相吻合;

## JavaScript 与 IEEE 754
JavaScript 采用 IEEE 754 标准，数值存储为64位双精度格式，数值精度最多可以达到 53 个二进制位（1 个隐藏位与 52 个有效位）。

64位分为三个部分：
- 符号位：第1位是正负数符号位，0代表正数（大于等于0），1代表负数。
- 指数位：中间的11位存储指数
- 尾数位：最后的52位是尾数，代表有效数字，大于等于1小于2

## 真值和机器数
例如：

+15 => 01111（2进制）

-8 => 11000（2进制）

真值是我们平时生活中用到的数字形式，比如+15，-8。机器数是存到机器里的形式，也就是2进制的形式，其中01111，第一个0是代表正数的意思，1111是保存的数值，转换成10进制就是15，合起来就是+15。11000同理。

## 单位
计算机内部，所有信息最终都是一个二进制值。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节(byte)。

转换关系：

8位 = 1字节

1024字节 = 1K

1024K = 1M

1024M = 1G

1024G = 1T

## 编码
### ASCII
0-32种状态规定了特殊用途,接收到约定好的这些字节，就要做一些约定的动作。又把所有的空格、标点符号、数字、大小写字母分别用连续的字节状态表示，一直编到了第 127 号，这样计算机就可以用不同字节来存储英语的文字了

这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的一位统一规定为0。

### GB2312
西欧一些国家用的不是英文，它们的字母在ASCII里没有为了可以保存他们的文字，他们使用127号这后的空位来保存新的字母，一直编到了最后一位255。
从128 到 255 这一页的字符集被称为扩展字符集。在不同编码中表示的也不同。

中国为了表示汉字，把127号之后的符号取消了，规定：
一个小于127的字符的意义与原来相同，但两个大于 127 的字符连在一起时，就表示一个汉字；
前面的一个字节（他称之为高字节）从0xA1用到0xF7，后面一个字节（低字节）从 0xA1 到 0xFE。
这样我们就可以组合出大约7000多个(247-161)*(254-161)=(7998)简体汉字了。
还把数学符号、日文假名和ASCII里原来就有的数字、标点和字母都重新编成两个字长的编码。这就是全角字符，127以下那些就叫半角字符。
把这种汉字方案叫做 GB2312。GB2312 是对 ASCII 的中文扩展

### GBK
不再要求低字节一定是 127 号之后的内码，只要第一个字节是大于 127 就固定表示这是一个汉字的开始,又增加了近 20000 个新的汉字（包括繁体字）和符号。
### Unicode
ISO 的国际组织废了所有的地区性编码方案，重新搞一个包括了地球上所有文化、所有字母和符 的编码！ Unicode 当然是一个很大的集合，现在的规模可以容纳100多万个符号。
ISO 就直接规定必须用两个字节，也就是 16 位来统一表示所有的字符，对于 ASCII 里的那些 半角字符，Unicode 保持其原编码不变，只是将其长度由原来的 8 位扩展为16 位，而其他文化和语言的字符则全部重新统一编码。
从 Unicode 开始，无论是半角的英文字母，还是全角的汉字，它们都是统一的一个字符！同时，也都是统一的 两个字节
注意：字节是一个8位的物理存贮单元， 而字符则是一个文化相关的符号。
### 平面（Plane）
Unicode 使用的数字是从 0 到 0x10ffff，这些数字都对有相对应的字符（当然，有的还没有编好，有的用作私人自定义）。每一个数字，就是一个代码点（Code Point）。
这些代码点，分为 17 个平面（Plane）。其实就是17 组。
Plane 3 到 Plane 14 还没有使用。
Plane 0，习惯上称作基本平面（Basic Plane）；剩余的称作扩展平面（Supplementary Plane）。
### utf-32
UTF-32 使用四个字节来表示存储代码点：把代码点转换为 32 位二进制，位数不够的左边充 0。
4个字节就是4 * 8 = 32位，就能表示2的32次方个数字，这些数字可以对应2的32次方个字符
### utf-16
UTF-16 用二个字节来表示基本平面，用四个字节来表示扩展平面。也就是说，UTF-16的编码长度要么是2个字节（U+0000到U+FFFF），要么是4个字节（U+010000到U+10FFFF）
### utf-8
UTF-8是一种变长的编码方法，字符长度从1个字节到4个字节不等。 越是常用的字符，字节越短，最前面的128个字符，只使用1个字节表示，与ASCII码完全相同。

### 中文在unicode里面的范围
4E00~9FA5：中日韩统一表意文字 其余有需要自查。4E00－9FA5 就是一般正则表达式匹配中文的范围。

### 在javascript中，如何转utf8呢？
可以使用encodeURIComponent

平时我们说中文是两个字节表示的，这个是错误的，几个字节表示完全是看编码，比如utf8和utf16有可能同样的unicode码，编码出来的字节数是不一样的。 我们平时的页面都是utf8编码的，其实在底层2进制上，中文通常是3个字节表示的。

### JavaScript 如何在内部使用 Unicode
虽然 JavaScript 源文件可以有任何类型的编码，但 JavaScript 会在执行之前在内部将其转换为 UTF-16。
JavaScript 字符串都是 UTF-16 序列，正如 ECMAScript 标准所说： 当 String 包含实际文本数据时，每个元素都被视为单个 UTF-16 代码单元。

## 定点数和浮点数
![img.png](/img/定点数和浮点数.png)

### 定点数
#### 无符号数
就是整个机器字长的全部二进制位均为数值位，没有符号位，相当于都是正数。机器字长是指计算机进行一次整数运算所能处理的二进制数据的位数，比如我们常说32位机器，64位机器。

比如8位无符号整数的范围就是 二进制： 00000000 - 11111111，转化为10进制就是0 - 255。

注意我们说的无符号数都是针对整数，没有小数。

#### 有符号数的定点表示
先来看看定点整数和定点小数如何在计算机里表示。
![image](https://user-images.githubusercontent.com/51157718/220058515-b25ffca7-db81-4fff-aeab-a32c80ab947f.png)

- 定点整数：符号位在第一位，通常0表示正数，1表示负数，小数点默认在最后一位，是隐藏的
- 定点小数：符号位在第一位，通常0表示正数，1表示负数，小数点隐藏在符号位后面，小数的数值部分也可以叫尾数，这个我们在浮点数介绍的时候会出现这个名词（数值部分 = 尾数）

定点数整数和小数都可以用原码，反码，补码表示，整数还可以用移码表示，具体什么意思我们稍后介绍。

> 在计算机中，小数点不占二进制位数

#### 原码
原码就是用尾数表示真值的绝对值，符号位（最高位）0表示正数，1表示负数。

假设我们机器字长为8位，我们拿 +19和 -19来解释一下。
![img.png](/img/+19和-19.png)

+19表示为：0，0010011 -19表示为: 1,0010011

下面是定点小数的表示：
![img.png](/img/+0.75和-0.75.png)

#### 反码
正数的反码 = 原码

负数的反码，则数值位全部取反，符号位不变

定点整数原码，反码取值范围：-2的N-1次方减1至2的N-1次方减1

#### 补码
正数的补码 = 原码

负数的补码 = 负数的反码 + 1

在计算机中均采用补码表示

补码算术运算过程中符号位和数值位都参与运算。

定点整数的补码取值范围：-2的N-1次方至2的N-1次方减1

#### 移码
补码的基础上符号位取反，只能表示整数。为什么需要移码，移码可以非常方便地判断两个数的大小。如下图：

![img.png](/img/移码.png)

我们会发现移码从左往右，只要先有1就更大，如果都有1，就往后面比，先出来1的就更大

> 补码和移码±0编码相同

#### 为什么需要补码移码
比如我们做一个运算 14 + (-14)，按道理应该等于0，但是我们把它们转为2进制，定点数的加法就出现问题了，居然不等于0，如下图：
![img.png](/img/14+-14.png)

那该怎么办呢，原码的加法需要变为减法也就是14-14，这样就对了，但是这意味我们的计算机既要设计一个加法器又要设计一个减法器，减法器的复杂度是很高的，
为了方便运算，一些聪明的人实现了让加法代替减法，这就需要我们之前讲的补码知识了。

14 + （-14）怎么才能计算正确呢?

我们可以让14的原码 加上 -14的补码，这时候就是 00001110 + 11110010（这个是-14的补码） = 100000000，因为机器字长是8位，
也就是最多容纳8位2进制，最左边的1会被机器天然丢弃，这样最终结果就是00000000.

### 浮点数
定点数对于很大的数字是特别浪费空间的，所以需要浮点数。举个例子，比如说浮点数1.2 x 10的20次方，我们知道是10进制，就只需要存1.2和20这些数据就能表示这个数，
但是定点数一个数字占一个坑，肯定没有浮点数在更小的空间表示更大的数。

我们举一个例子来理解浮点数的表示，比如数字+302657264526，这是定点整数的表示方法，如果是科学计数法，我们表示为：+3.026 * 1011 ，而其中的10是不是固定不变的呢，
所以如果要保存这个科学技术法表示的数字，我们可以不看10这个基数，只需要保存+11 和 +3.026就能推出这个数字的科学技术法，从而得到这个数字

我们可以给+11 和 +3.026取两个名字，在浮点数里分别叫阶码和尾数，如下图：

![img.png](/img/浮点数表示.png)

注意阶码分为了阶符和阶码的数值部分，尾数分为数符和尾数的数值部分。

阶符是正表示小数点往后移，为负表示小数点往前移动。阶码表示小数点移动多少位。

数符表示数值的正负性，尾数表示数字精度。

其中， 阶码反映数值的大小，尾数反应数值的精度，为什么这么说呢，比如之前举的例子中，+11表示小数点要右移多少位，是不是越大，移动的位数越多，数字就越大呢，
对于尾数，比如+3.0265748是不是同样右移5位比+3.026表示的数字更精确呢

在二进制表示的计算机内，阶码常用补码或者移码表示的定点整数，尾数常用原码或者补码表示的定点小数。

浮点数的表示为 N = rE * M ， r相当于底数，是2（跟10进制科学计数法是10时意思是一样的），E代表阶码，M代表尾数。

## R进制
### 不同进制的表示
有后缀和下标（即对应进制的数字）表示。如二进制：(10)B 和 (10)₂
八进制，十进制和十六进制的后缀分别是O, D, H。

> 16进制中 10 开始的数字用从大写字母 A 开始的字母来表示。

## 不同进制的转换
1、任意进制转十进制。
- 每位数字乘以对应进制的位数次方后相加，位从0开始，从右开始数。例如：2进制的 101.1 = 1 x 2的2次方 + 0 x 2的1次方 + 1 x 2的0次方 + 1 x 2的-1次方
- JS：toString(radix)

> 涉及数值运算的时候，用后缀或下标表示法书写结果。 

2、十进制整数转为任意进制。
- 除商取余法。除对应进制。将余数由后往前拼接得到结果。
- JS：parseInt(num, radix);小数部分被截断。

例如：把89化为二进制的数：除二取余，倒序排列，高位补零。

89÷2=44 余1

44÷2=22 余0

22÷2=11 余0

11÷2=5 余1

5÷2=2 余1

2÷2=1 余0

1÷2=0 余1

结果：1011001

3、十进制小数转二进制小数

方式是采用“乘2取整，顺序排列”法。

1. 用2乘十进制小数，可以得到积，将积的整数部分取出（1或0）
2. 取出积的小数部分，再用2乘，又得到一个积，再将积的整数部分取出（1或0）
3. 如此进行，直到积中的小数部分为零，或者达到所要求的精度为止

如: 十进制 0.25 转为二进制

0.25 * 2 = 0.5 取出整数部分：0

0.5 * 2 = 1.0 取出整数部分1

即十进制0.25的二进制为 0.01 ( 第一次所得到为最高位,最后一次得到为最低位)。

而0.1和0.2转换成二进制是无限循环的。所以0.1+0.2!==0.3

4、十进制份数转二进制
可以将分数转为以2为底的负幂次方数的更小的分数的和，顺序是从大到小。然后按顺序从2的负一次方开始找，也就是二分之一开始，看看和里面有没有这个数，没有的话对应二进制为0。
（小数点后第一位对应2的负一次方）。

如53/64，2的负一次方是二分之一，2的负二次方是四分之一，2的负三次方是八分之一。可以分为32/64，16/64，4/64和1/64的和。对应着二进制(0.110101)₂

5、二进制转八进制
三位合一法：从低位到高位每3位二进制转为1位八进制，然后按原顺序取值。

6、二进制转十六进制
四位合一法。

7、八（十六）进制转二进制
每1位八进制进制转3位二进制
每1位十六进制进制转4位二进制

## JavaScript中的进制
### 进制表示
```
let a = 0b10100;//二进制
let b = 0o24;//八进制
let c = 20;//十进制
let d = 0x14;//十六进制
```
### 进制转换
- 10进制转任意进制 10进制数.toString(目标进制)
- 任意进制转十进制 parseInt('任意进制字符串', 原始进制)，小数部分会被截断;

## localhost 和 127.0.0.1
127.0.0.1是属于回环地址。回环地址会将所有发往该地址的数据包loop back。

localhost 是默认情况下都指向了 IPV4的 127.0.0.1 和 IPV6 的 ::1。

在hosts文件中可以指定给定域名对应的 IP 地址。

## 资料
[前端计算机基础大补丸在此！来一颗吧！](https://juejin.cn/post/7112318717798645768)
[海明码](https://blog.csdn.net/Yonggie/article/details/83186280)
